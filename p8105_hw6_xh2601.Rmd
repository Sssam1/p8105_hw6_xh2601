---
title: "p8105_hw6_xh2601"
output: github_document
---

```{r setup, message = FALSE}
# load the tidyverse library
library(tidyverse)
library(modelr)
set.seed(1)
```

The general format for plots making

```{r}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .8,
  out.width = "90%",
  dpi = 200
)

theme_set(
  theme_minimal() + 
    theme(legend.position = "bottom",
          plot.title = element_text(hjust = 0.5))
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

1. Create a city_state variable (e.g. “Baltimore, MD”), and a binary variable indicating whether the homicide is solved. Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO – these don’t report victim race. Also omit Tulsa, AL – this is a data entry mistake. For this problem, limit your analysis those for whom victim_race is white or black. Be sure that victim_age is numeric.

```{r}
# import the dataset
# use mutate() to create the city_state variable
# use mutate() to create a variable to indicate whether the case is unsolved
# use mutate() to make sure victim_age is numeric
# use filter() remove the unwanted rows
homicide_df = read_csv("data/homicide-data.csv") |> 
  janitor::clean_names() |> 
  mutate(
    city_state = str_c(city, ", ", state),
    solved = (!disposition %in% c("Closed without arrest", "Open/No arrest")),
    victim_age = as.numeric(victim_age)
  ) |> 
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black")
  )
```

2. For the city of Baltimore, MD, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors. Save the output of glm as an R object; apply the broom::tidy to this object; and obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed.

```{r}
# create a df for baltimore
# select variables of interest
baltimore_df = homicide_df |> 
  filter(city_state == "Baltimore, MD") |> 
  select(uid, victim_race, victim_age, victim_sex, solved)

# fit glm logistic model 
# apply broom::tidy() and exponentiate the estimate
baltimore_logit = 
  glm(
    solved ~ victim_race + victim_age + victim_sex,
    data = baltimore_df,
    family = binomial(link = "logit")) |> 
  broom::tidy(
    exponentiate = TRUE,
    conf.int = TRUE)

# get odds ration estimate and CI
baltimore_logit |> 
  filter(term == "victim_sexMale") |> 
  select(term, estimate, conf.low, conf.high) |> 
  knitr::kable()
```

3. Now run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims. Do this within a “tidy” pipeline, making use of purrr::map, list columns, and unnest as necessary to create a dataframe with estimated ORs and CIs for each city.

```{r}
# create a function to fit logistic regression for each city
homicide_sex_logit = function(df){
  glm(
    solved ~ victim_race + victim_age + victim_sex,
    data = df,
    family = binomial(link = "logit")) |> 
  broom::tidy(
    exponentiate = TRUE,
    conf.int = TRUE) |> 
  filter(term == "victim_sexMale") |> 
  select(term, estimate, conf.low, conf.high)
}
```

```{r}
# select the variables of interest, nest on city_state
# map on the homicide_sex_logit() function for each nested dataframe
# unnest the result
homicide_sex = homicide_df |> 
  select(uid, city_state, victim_race, victim_age, victim_sex, solved) |> 
  nest(data = -city_state) |> 
  mutate(
    results = map(data, homicide_sex_logit)
  ) |> 
  select(-data) |> 
  unnest()
homicide_sex |> knitr::kable()
```

4. Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.

```{r}
homicide_sex |> 
  mutate(city_state = fct_reorder(city_state, estimate)) |> 
  ggplot(aes(x = estimate, y = city_state)) +
  geom_point() +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0.2) +
  labs(
    x = "Estimated Odds Ratio and 95% CI for Solving Homicides (Male vs Female)",
    y = "City, State",
    title = "Estimated Odds Ratios (Male vs Female) for Solving Homicides by City \n(adjusted for age and race)"
  )
```

Based on the plot, most cities have estimated odds ratios below 1, indicating that homicides involving male victims are less likely to be solved compared to those involving female victims, after adjusting for age and race. However, some of these odds ratios are not statistically significant, as their confidence intervals include 1. Only a few cities show odds ratios above 1, suggesting male-victim homicides being more likely to be solved, but none of these estimates are statistically significant, as their confidence intervals all span 1. Overall, in most cities, the odds of a homicide being solved are lower for male victims when compared to female victims, adjusted for age and race, although the statistical significance varies by city and is often inconclusive due to wide confidence intervals.

## Problem 2

1. For this problem, we’ll use the Central Park weather data we’ve seen elsewhere. The code chunk below will import these data from the p8105.datasets package. We’ll focus on a simple linear regression with tmax as the response with tmin and prcp as the predictors, and are interested in the distribution of two quantities estimated from these data: r_hat square, beta1_hat/beta2_hat

```{r}
# load package
library(p8105.datasets)
data("weather_df")
```

```{r}
# clean the dataset with CentralPark_NY and variables of interest
weather_df = weather_df |> 
  filter(name == "CentralPark_NY") |> 
  select(tmin, prcp, tmax)
```

2. Use 5000 bootstrap samples and, for each bootstrap sample, produce estimates of these two quantities. 

```{r}
# create a function to get the beta ratio for beta1 = tmin, beta2 = prcp
get_beta_ratio = function(model) {
  coefs = broom::tidy(model)
  beta1 = coefs$estimate[coefs$term == "tmin"]
  beta2 = coefs$estimate[coefs$term == "prcp"]
  beta1 / beta2
}
```

```{r}
# bootstrap for 5000 samples, fit linear model, and get estimates
bootstrap_weather = weather_df |> 
  bootstrap(n = 5000) |> 
  mutate(
    df = map(strap, as_tibble),
    models = map(df, \(df) lm(tmax ~ tmin + prcp, data = df) ),
    r2 = map_dbl(models, \(m) broom::glance(m)$r.squared),
    beta_ratio = map_dbl(models, get_beta_ratio)) |> 
  select(-strap, -models, -df)
bootstrap_weather
```

3. Plot the distribution of your estimates, and describe these in words. 

```{r}
# density plot for r^2
bootstrap_weather |> 
  ggplot(aes(x = r2)) +
  geom_density(fill = "skyblue", alpha = 0.8) +
  labs(
    x = "R-squared",
    title = "Bootstrap Distribution of R-squared")
```

The distribution of R-squared in bootstrap samples is unimodal and approximately symmetric around 0.913, and slightly left skewed. The distribution means the r_hat square estimates are relatively stable, so the linear model using tmin and prcp as predictors could explain about 91% of changes in tmax.

```{r}
# density plot for beta ratio
bootstrap_weather |> 
  ggplot(aes(x = beta_ratio)) +
  geom_density(fill = "skyblue", alpha = 0.8) +
  labs(
    x = "Beta Ratio",
    title = "Bootstrap Distribution of Beta Ratio")
```

The bootstrap distribution of the beta ratio shows a sharp peak near 0, with extremely long tails on both sides of the density plot. The long-tailed shape occurs because precipitation (prcp) takes the value zero on for more than half of the days in the original dataset, so many bootstrap samples contain little variation in prcp. In such samples, the estimated coefficient beta2 for prcp would be very small, causing the ratio of beta1 / beta2 to explode to extremely large absolute values, especially on the negative side.

To visualize the central behavior of the ratio, the following histogram looks at only the middle 98% of the bootstrap distribution (the 1%–99% interval). Within this trimmed range, the majority of values cluster around a central peak on a negative ratio, while both tails remain wide. This reflects instability in the denominator beta2, and the ratio is hard to be interpreted in this sample.

```{r}
# only plot between 1%-99% interval
small_ratio = quantile(bootstrap_weather$beta_ratio, 0.01, na.rm = TRUE)
large_ratio = quantile(bootstrap_weather$beta_ratio, 0.99, na.rm = TRUE)

interval_data = bootstrap_weather |> 
  filter(beta_ratio > small_ratio, beta_ratio < large_ratio)

ggplot(interval_data, aes(beta_ratio)) +
  geom_histogram(fill = "skyblue", alpha = 0.8) +
  labs(
    x = "Beta Ratio",
    title = "Bootstrap Distribution of Beta Ratio (1% - 99% Interval)")
```

4. Using the 5000 bootstrap estimates, identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval

```{r}
# get 95% CI for both 
ci_results = bootstrap_weather |> 
  summarize(
    r2_ci_lower = quantile(r2, 0.025), 
    r2_ci_upper = quantile(r2, 0.975),
    beta_ratio_ci_lower = quantile(beta_ratio, 0.025), 
    beta_ratio_ci_upper = quantile(beta_ratio, 0.975))
ci_results |> knitr::kable()
```

The 95% confidence interval for R-squared is `r ci_results$r2_ci_lower` to `r ci_results$r2_ci_upper`, the The 95% confidence interval for beta ratio is `r ci_results$beta_ratio_ci_lower` to `r ci_results$beta_ratio_ci_upper`.

## Problem 3

1. Load and clean the data for regression analysis (i.e. use appropriate variable names, convert numeric to factor where appropriate, check for the presence of missing data, etc.).

```{r}
# import data
# convert some variables to factors
birthweight_df = read_csv("data/birthweight.csv") |> 
  janitor::clean_names() |> 
  mutate(
    babysex = factor(babysex,
                     levels = c(1, 2),
                     labels = c("male", "female")),
    frace = factor(frace,
                   levels = c(1, 2, 3, 4, 8, 9),
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")),
    malform = factor(malform,
                     levels = c(0, 1),
                     labels = c("absent", "present")),
    mrace = factor(mrace,
                   levels = c(1, 2, 3, 4, 8),
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other"))
  )
# check missing data in the dataset
sum(is.na(birthweight_df))
```

2. Propose a regression model for birthweight. This model may be based on a hypothesized structure for the factors that underly birthweight, on a data-driven model-building process, or a combination of the two. Describe your modeling process and show a plot of model residuals against fitted values – use add_predictions and add_residuals in making this plot.

**Model building:** Birthweight is influenced by a combination of maternal physiological characteristics and pregnancy-related developmental factors. Maternal height and pre-pregnancy weight reflect long-term nutritional status and genetic influences on fetal growth. In addition, weight gain during pregnancy and gestational age in weeks are indicators of the adequacy of fetal development and duration of intrauterine growth. Consistent with findings reported in the [literature](https://pmc.ncbi.nlm.nih.gov/articles/PMC11608488/), maternal height, pre-pregnancy weight, and pregnancy weight gain were consistently associated with birthweight. Based on these hypothesized mechanisms and empirical support, I propose a regression model using maternal pre-pregnancy BMI (**ppbmi**), mother’s weight gain during pregnancy in pounds (**wtgain**), and gestational age in weeks (**gaweeks**), as the predictors of baby’s birth weight in grams (**bwt**).

```{r}
# construct my model
bwt_my_model = lm(bwt ~ ppbmi + wtgain + gaweeks, data = birthweight_df)
summary(bwt_my_model)
```

The results show that all three predictors have statistically significant positive associations with birthweight.

```{r}
# show a plot of model residuals against fitted values
birthweight_df |> 
  add_residuals(bwt_my_model) |> 
  add_predictions(bwt_my_model) |> 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.2) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    x = "Fitted Values",
    y = "Residuals",
    title = "Residuals vs Fitted Values for Birth Weight Prediction Model"
  )
```

The plot shows that residuals appear to be randomly scattered around 0 with no strong pattern, forming a roughly symmetric cloud.

3. Compare your model to two others:

One using length at birth and gestational age as predictors (main effects only)
```{r}
# construct model 1
bwt_model1 = lm(bwt ~ blength + gaweeks, data = birthweight_df)
summary(bwt_model1)
```

One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
```{r}
# construct model 2
bwt_model2 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = birthweight_df)
summary(bwt_model2)
```

4. Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate.

```{r}
# create functions to construct models
model_bwt = function(df) {
  lm(bwt ~ ppbmi + wtgain + gaweeks, data = df)
}

model_1 = function(df) {
  lm(bwt ~ blength + gaweeks, data = df)
}

model_2 = function(df) {
  lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = df)
}
```

```{r}
# use crossv_mc() for cross validation
# fit all three models for training set
# get rmse for all three fits in testing set
cv_df =
  crossv_mc(birthweight_df, n = 100) |>
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble),
    fit_bwt = map(train, model_bwt),
    fit_1 = map(train, model_1),
    fit_2 = map(train, model_2),
    rmse_bwt = map2_dbl(fit_bwt, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_1 = map2_dbl(fit_1, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_2 = map2_dbl(fit_2, test, \(mod, df) rmse(model = mod, data = df))
  )

# make comparison in plot
cv_df |> 
  select(starts_with("rmse")) |> 
  rename(
    "proposed model" = "rmse_bwt",
    "model 1" = "rmse_1",
    "model 2" = "rmse_2") |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse") |> 
  mutate(model = fct_inorder(model)) |>
  ggplot(aes(x = model, y = rmse)) + geom_violin() +
  labs(
    x = "Model",
    y = "Cross Validation Prediction Error",
    title = "RMSE of Three Prediction Models"
  )
```

As shown in the RMSE distributions, Model 2 has the smallest prediction error, while my proposed model has the largest RMSE. This indicates that Model 2 provides the most accurate predictions of birth weight among the three models, suggesting that maternal characteristics alone are less informative for predicting baby birth weight compared with newborn measurements and their interactions. 




